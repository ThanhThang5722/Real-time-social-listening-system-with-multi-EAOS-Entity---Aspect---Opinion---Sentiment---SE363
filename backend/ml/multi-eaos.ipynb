{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7a7405e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sentencepiece protobuf --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b18da97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import logging\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from transformers import AutoTokenizer\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6di20vdmlzm",
   "metadata": {},
   "source": [
    "# üéØ Multi-EAOS Model - Production Ready\n",
    "\n",
    "## Improvements in This Notebook\n",
    "\n",
    "### ‚úÖ Data Management\n",
    "- Train/Validation split (80/20) for proper model evaluation\n",
    "- Prevents overfitting and enables model selection\n",
    "\n",
    "### ‚úÖ Training Process\n",
    "- **Validation loop** to monitor generalization performance\n",
    "- **Early stopping** (patience: 20 epochs) to prevent overfitting\n",
    "- **Best model selection** based on validation F1-score\n",
    "- **Periodic checkpoints** (every 10 epochs) for training resume\n",
    "\n",
    "### ‚úÖ Evaluation Metrics\n",
    "- **Accuracy**: Overall correctness of predictions\n",
    "- **Precision**: Ratio of correct predictions among all predictions\n",
    "- **Recall**: Ratio of correct predictions among all ground truth samples\n",
    "- **F1-Score**: Harmonic mean of Precision and Recall\n",
    "- Real-time metrics tracking during training and validation\n",
    "- Comprehensive evaluation function for test sets\n",
    "\n",
    "### ‚úÖ Model Persistence\n",
    "- Organized folder structure:\n",
    "  - `models/checkpoints/` - Training checkpoints\n",
    "  - `models/best_model/` - Best model + config for deployment\n",
    "- Saves model configuration (config.json) with:\n",
    "  - Label mappings\n",
    "  - Training metrics (accuracy, precision, recall, F1-score)\n",
    "  - Model hyperparameters\n",
    "- Easy model loading for inference\n",
    "\n",
    "### ‚úÖ Backend Integration\n",
    "- `EAOSInference` class for production use\n",
    "- Confidence threshold filtering\n",
    "- Batch prediction support\n",
    "- Ready for FastAPI/Flask integration\n",
    "\n",
    "### üöÄ Quick Start\n",
    "1. Run all cells to prepare data and define model\n",
    "2. Execute training: `run_training(train_dataset, val_dataset)`\n",
    "3. Best model automatically saved to `models/best_model/`\n",
    "4. Use `EAOSInference` class in your backend\n",
    "5. Evaluate model performance with comprehensive metrics\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "508c6f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# C·∫•u h√¨nh log ƒë·ªÉ d·ªÖ theo d√µi l·ªói\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def find_span_indices(text, phrase):\n",
    "    \"\"\"\n",
    "    T√¨m v·ªã tr√≠ b·∫Øt ƒë·∫ßu v√† k·∫øt th√∫c c·ªßa m·ªôt c·ª•m t·ª´ trong c√¢u.\n",
    "    Tr·∫£ v·ªÅ (start_char_idx, end_char_idx).\n",
    "    \"\"\"\n",
    "    if not phrase or phrase.lower() == \"null\" or phrase == \"\":\n",
    "        return (-1, -1)  # X·ª≠ l√Ω tr∆∞·ªùng h·ª£p Implicit (·∫©n)\n",
    "\n",
    "    start_idx = text.lower().find(phrase.lower())\n",
    "    if start_idx == -1:\n",
    "        return None  # Kh√¥ng t√¨m th·∫•y kh·ªõp\n",
    "\n",
    "    end_idx = start_idx + len(phrase)\n",
    "    return (start_idx, end_idx)\n",
    "\n",
    "# --- PH·∫¶N THAY ƒê·ªîI L·ªöN: ƒê·ªåC JSON M·ªöI ---\n",
    "def process_json_array_data(file_path):\n",
    "    processed_data = []\n",
    "\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            full_content = f.read()\n",
    "\n",
    "        # Ph√¢n t√≠ch JSON\n",
    "        raw_json = json.loads(full_content)\n",
    "\n",
    "        # L·∫•y m·∫£ng t·ª´ key \"results\" thay v√¨ l√† JSON Array tr·ª±c ti·∫øp\n",
    "        raw_entries = raw_json.get(\"results\", [])\n",
    "        if not isinstance(raw_entries, list):\n",
    "            logger.error(\"Key 'results' kh√¥ng ph·∫£i l√† m·∫£ng. Ki·ªÉm tra l·∫°i file JSON.\")\n",
    "            return []\n",
    "\n",
    "    except json.JSONDecodeError as e:\n",
    "        logger.error(f\"L·ªñI L·ªöN: T·ªáp tin kh√¥ng ph·∫£i l√† JSON h·ª£p l·ªá. L·ªói t·∫°i char {e.pos}: {e}\")\n",
    "        return []\n",
    "    except Exception as e:\n",
    "        logger.error(f\"L·ªói khi ƒë·ªçc file: {e}\")\n",
    "        return []\n",
    "\n",
    "    for i, entry in enumerate(raw_entries):\n",
    "        try:\n",
    "            text = entry[\"text\"]\n",
    "            labels = entry[\"labels\"]\n",
    "        except KeyError as e:\n",
    "            logger.warning(f\"M·∫´u {i+1}: Thi·∫øu key {e} trong ƒë·ªëi t∆∞·ª£ng JSON. B·ªè qua.\")\n",
    "            continue\n",
    "\n",
    "        valid_labels = []\n",
    "        for label in labels:\n",
    "            entity_span = find_span_indices(text, label['entity'])\n",
    "            opinion_span = find_span_indices(text, label['opinion'])\n",
    "\n",
    "            if entity_span is None:\n",
    "                logger.warning(f\"M·∫´u {i+1}: Kh√¥ng t√¨m th·∫•y Entity '{label.get('entity')}' trong text.\")\n",
    "                continue\n",
    "            if opinion_span is None:\n",
    "                logger.warning(f\"M·∫´u {i+1}: Kh√¥ng t√¨m th·∫•y Opinion '{label.get('opinion')}' trong text.\")\n",
    "                continue\n",
    "\n",
    "            new_label = {\n",
    "                \"entity_text\": label['entity'],\n",
    "                \"entity_span\": entity_span,\n",
    "                \"opinion_text\": label['opinion'],\n",
    "                \"opinion_span\": opinion_span,\n",
    "                \"aspect\": label['aspect'],\n",
    "                \"sentiment\": label['sentiment']\n",
    "            }\n",
    "            valid_labels.append(new_label)\n",
    "\n",
    "        if valid_labels:\n",
    "            processed_data.append({\n",
    "                \"text\": text,\n",
    "                \"labels\": valid_labels\n",
    "            })\n",
    "\n",
    "    return processed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a157504",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:__main__:L·ªói khi ƒë·ªçc file: [Errno 2] No such file or directory: './filtered.json'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ƒê√£ x·ª≠ l√Ω th√†nh c√¥ng 0 m·∫´u d·ªØ li·ªáu.\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-1389206397.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_json_array_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./filtered.json'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"ƒê√£ x·ª≠ l√Ω th√†nh c√¥ng {len(data)} m·∫´u d·ªØ li·ªáu.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "data = process_json_array_data('./filtered.json')\n",
    "print(f\"ƒê√£ x·ª≠ l√Ω th√†nh c√¥ng {len(data)} m·∫´u d·ªØ li·ªáu.\")\n",
    "print(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b9cf161",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. C·∫•u h√¨nh c√°c nh√£n (Mapping)\n",
    "# D·ª±a theo b√†i b√°o: 5 nh√≥m Aspect v√† 3 nh√≥m Sentiment\n",
    "ASPECT_MAP = {\n",
    "    \"ƒê·ªãa ƒëi·ªÉm\": 1,\n",
    "    \"K·ªãch b·∫£n\": 2,\n",
    "    \"D√†n d·ª±ng\": 3,\n",
    "    \"D√†n cast\": 4,\n",
    "    \"Kh√°ch m·ªùi\": 5,\n",
    "    \"Kh·∫£ nƒÉng ch∆°i tr√≤ ch∆°i\": 6,\n",
    "    \"Qu·∫£ng c√°o\": 7,\n",
    "    \"Th·ª≠ th√°ch\": 8,\n",
    "    \"T∆∞∆°ng t√°c gi·ªØa c√°c th√†nh vi√™n\": 9,\n",
    "    \"Tinh th·∫ßn ƒë·ªìng ƒë·ªôi\": 10,\n",
    "    \"Kh√°c\": 0\n",
    "}\n",
    "SENTIMENT_MAP = {\n",
    "    \"t√≠ch c·ª±c\": 1,\n",
    "    \"ti√™u c·ª±c\": 2,\n",
    "    \"trung t√≠nh\": 0,\n",
    "}\n",
    "\n",
    "# T·∫£i Tokenizer c·ªßa PhoBERT (d√πng b·∫£n base ho·∫∑c v2 ƒë·ªÅu ƒë∆∞·ª£c)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"vinai/phobert-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4ad7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"vinai/phobert-base\", use_fast=True)\n",
    "    print(\"ƒê√£ load Fast Tokenizer th√†nh c√¥ng!\")\n",
    "except Exception as e:\n",
    "    print(f\"Kh√¥ng th·ªÉ load Fast Tokenizer: {e}\")\n",
    "    # N·∫øu l·ªói n√†y x·∫£y ra, b·∫°n bu·ªôc ph·∫£i d√πng C√°ch 2 b√™n d∆∞·ªõi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41198e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EAOSDatasetManual(Dataset):\n",
    "    def __init__(self, data, tokenizer, max_len=256, max_quads=4):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        self.max_quads = max_quads\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def manual_find_token_span(self, encoding, char_span):\n",
    "        \"\"\"\n",
    "        H√†m th·ªß c√¥ng ƒë·ªÉ √°nh x·∫° (char_start, char_end) -> (token_start, token_end)\n",
    "        D√πng cho Slow Tokenizer kh√¥ng c√≥ offset_mapping.\n",
    "        \"\"\"\n",
    "        char_start, char_end = char_span\n",
    "        if char_start == -1: return 0, 0 # Implicit\n",
    "\n",
    "        # Tokenizer Slow tr·∫£ v·ªÅ input_ids. Ta c·∫ßn convert ng∆∞·ª£c l·∫°i tokens ƒë·ªÉ ki·ªÉm tra ƒë·ªô d√†i\n",
    "        tokens = self.tokenizer.convert_ids_to_tokens(encoding['input_ids'][0])\n",
    "\n",
    "        # T·∫°o l·∫°i map th·ªß c√¥ng\n",
    "        current_char_idx = 0\n",
    "        token_spans = [] # List l∆∞u [(start, end), (start, end)...] cho t·ª´ng token\n",
    "\n",
    "        # L∆∞u √Ω: PhoBERT d√πng BPE v√† k√Ω t·ª± '_' thay cho kho·∫£ng tr·∫Øng, ho·∫∑c '@@'\n",
    "        # Logic n√†y ch·ªâ mang t√≠nh t∆∞∆°ng ƒë·ªëi cho PhoBERT, c·∫ßn c·∫©n th·∫≠n v·ªõi special tokens\n",
    "        for token in tokens:\n",
    "            # B·ªè qua special tokens ban ƒë·∫ßu (nh∆∞ <s>)\n",
    "            if token in [self.tokenizer.bos_token, self.tokenizer.eos_token, self.tokenizer.pad_token]:\n",
    "                token_len = 0\n",
    "            else:\n",
    "                # Clean token ƒë·ªÉ t√≠nh ƒë·ªô d√†i th·ª±c t·∫ø trong c√¢u\n",
    "                clean_token = token.replace('@@', '').replace('_', ' ')\n",
    "                token_len = len(clean_token)\n",
    "\n",
    "            # N·∫øu l√† token ƒë·∫ßu ti√™n (sau <s>), c√≥ th·ªÉ c·∫ßn strip kho·∫£ng tr·∫Øng th·ª´a n·∫øu c√≥\n",
    "            start = current_char_idx\n",
    "            end = current_char_idx + token_len\n",
    "            token_spans.append((start, end))\n",
    "\n",
    "            # C·∫≠p nh·∫≠t v·ªã tr√≠ con tr·ªè (gi·∫£ ƒë·ªãnh token n·ªëi ti·∫øp nhau kh√≠t)\n",
    "            # V·ªõi PhoBERT Slow, logic n√†y c√≥ th·ªÉ l·ªách 1-2 k√Ω t·ª± do c√°ch x·ª≠ l√Ω d·∫•u c√°ch\n",
    "            # ƒê√¢y l√† ƒëi·ªÉm y·∫øu c·ªßa Slow Tokenizer.\n",
    "            current_char_idx += token_len\n",
    "\n",
    "        # T√¨m token index d·ª±a tr√™n char index\n",
    "        token_start, token_end = -1, -1\n",
    "\n",
    "        # Logic so kh·ªõp g·∫ßn ƒë√∫ng (Approximate Matching)\n",
    "        for idx, (t_start, t_end) in enumerate(token_spans):\n",
    "            # N·∫øu span c·ªßa token giao nhau v·ªõi span c·ªßa entity\n",
    "            if t_start <= char_start < t_end:\n",
    "                token_start = idx\n",
    "            if t_start < char_end <= t_end:\n",
    "                token_end = idx\n",
    "\n",
    "        if token_start != -1 and token_end == -1: token_end = token_start # S·ª≠a l·ªói n·∫øu ch·ªâ b·∫Øt ƒë∆∞·ª£c start\n",
    "\n",
    "        return (token_start, token_end) if (token_start != -1) else (0, 0)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.data[idx]\n",
    "        text = item['text']\n",
    "        labels = item['labels']\n",
    "\n",
    "        # KH√îNG D√ôNG return_offsets_mapping n·ªØa\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            max_length=self.max_len,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        # N·∫øu d√πng C√°ch 1 th√†nh c√¥ng (Fast), b·∫°n c√≥ th·ªÉ uncomment d√≤ng n√†y ƒë·ªÉ l·∫•y offset\n",
    "        # offset_mapping = encoding.offset_mapping[0] if encoding.is_fast else None\n",
    "\n",
    "        target_matrix = np.full((self.max_quads, 6), -1, dtype=int)\n",
    "\n",
    "        for i, label in enumerate(labels):\n",
    "            if i >= self.max_quads: break\n",
    "\n",
    "            # D√πng h√†m manual\n",
    "            e_s, e_e = self.manual_find_token_span(encoding, label['entity_span'])\n",
    "            o_s, o_e = self.manual_find_token_span(encoding, label['opinion_span'])\n",
    "\n",
    "            asp_id = ASPECT_MAP.get(label['aspect'], 4)\n",
    "            sent_id = SENTIMENT_MAP.get(label['sentiment'], 2)\n",
    "\n",
    "            target_matrix[i] = [e_s, e_e, o_s, o_e, asp_id, sent_id]\n",
    "\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].squeeze(),\n",
    "            'attention_mask': encoding['attention_mask'].squeeze(),\n",
    "            'targets': torch.tensor(target_matrix, dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1818691",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = EAOSDatasetManual(data, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "h7vp9yrea9h",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train/validation sets (80/20)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_data, val_data = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = EAOSDatasetManual(train_data, tokenizer)\n",
    "val_dataset = EAOSDatasetManual(val_data, tokenizer)\n",
    "\n",
    "print(f\"Training samples: {len(train_dataset)}\")\n",
    "print(f\"Validation samples: {len(val_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e03fa916",
   "metadata": {},
   "outputs": [],
   "source": [
    "# L·∫•y th·ª≠ m·∫´u ƒë·∫ßu ti√™n\n",
    "sample = ds[0]\n",
    "\n",
    "print(\"Input IDs shape:\", sample['input_ids'].shape) # N√™n l√† [256]\n",
    "print(\"Targets shape:\", sample['targets'].shape)     # N√™n l√† [5, 6]\n",
    "print(\"M·∫´u Targets ƒë·∫ßu ti√™n:\\n\", sample['targets'])\n",
    "print(\"Decode th·ª≠ input:\", tokenizer.decode(sample['input_ids']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037a3e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import AutoModel\n",
    "\n",
    "class MultiEAOSModel(nn.Module):\n",
    "    def __init__(self, model_name=\"vinai/phobert-base\",\n",
    "                 num_aspects=11,\n",
    "                 num_sentiments=3,\n",
    "                 max_len=256,\n",
    "                 max_quads=4,\n",
    "                 hidden_dim=256):\n",
    "        super(MultiEAOSModel, self).__init__()\n",
    "\n",
    "        # 1. BERT Encoder (PhoBERT) [cite: 12, 45]\n",
    "        # D√πng ƒë·ªÉ m√£ h√≥a ng·ªØ nghƒ©a ng·ªØ c·∫£nh ti·∫øng Vi·ªát\n",
    "        self.bert = AutoModel.from_pretrained(model_name)\n",
    "        self.bert_hidden_size = self.bert.config.hidden_size # Th∆∞·ªùng l√† 768\n",
    "\n",
    "        # 2. BiLSTM Layer [cite: 161, 163]\n",
    "        # H·ªçc ph·ª• thu·ªôc xa v√† ng·ªØ c·∫£nh hai chi·ªÅu\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=self.bert_hidden_size,\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=1,\n",
    "            batch_first=True,\n",
    "            bidirectional=True\n",
    "        )\n",
    "        # BiLSTM output size = hidden_dim * 2 (do 2 chi·ªÅu)\n",
    "        self.lstm_out_dim = hidden_dim * 2\n",
    "\n",
    "        # 3. Learnable Queries & Attention\n",
    "        # ƒê·ªÉ d·ª± ƒëo√°n Max_Quads b·ªô t·ª© c√πng l√∫c, ta t·∫°o ra c√°c \"Query Vectors\"\n",
    "        # M·ªói Query ƒë·∫°i di·ªán cho m·ªôt \"khe ch·ª©a\" b·ªô t·ª© ti·ªÅm nƒÉng\n",
    "        self.quad_queries = nn.Parameter(torch.randn(max_quads, self.lstm_out_dim))\n",
    "\n",
    "        # Multi-Head Attention: Queries (Quad Slots) t√¨m ki·∫øm th√¥ng tin t·ª´ Key/Value (BiLSTM Output)\n",
    "        self.attention = nn.MultiheadAttention(\n",
    "            embed_dim=self.lstm_out_dim,\n",
    "            num_heads=4,\n",
    "            batch_first=True\n",
    "        )\n",
    "\n",
    "        # 4. Prediction Heads (6 ƒë·∫ßu ra cho m·ªói Quad) [cite: 169]\n",
    "        # Output: (Entity_Start, Entity_End, Opinion_Start, Opinion_End, Aspect, Sentiment)\n",
    "\n",
    "        # D·ª± ƒëo√°n v·ªã tr√≠ trong c√¢u (Pointer Network) -> Output size = max_len\n",
    "        self.fc_e_start = nn.Linear(self.lstm_out_dim, max_len)\n",
    "        self.fc_e_end   = nn.Linear(self.lstm_out_dim, max_len)\n",
    "        self.fc_o_start = nn.Linear(self.lstm_out_dim, max_len)\n",
    "        self.fc_o_end   = nn.Linear(self.lstm_out_dim, max_len)\n",
    "\n",
    "        # D·ª± ƒëo√°n ph√¢n lo·∫°i\n",
    "        self.fc_aspect    = nn.Linear(self.lstm_out_dim, num_aspects)\n",
    "        self.fc_sentiment = nn.Linear(self.lstm_out_dim, num_sentiments)\n",
    "\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        # --- A. Encoding Phase ---\n",
    "        # Output PhoBERT: (Batch, Seq_Len, 768)\n",
    "        bert_out = self.bert(input_ids=input_ids, attention_mask=attention_mask)[0]\n",
    "\n",
    "        # Output BiLSTM: (Batch, Seq_Len, Hidden_Dim * 2)\n",
    "        lstm_out, _ = self.lstm(bert_out)\n",
    "\n",
    "        # --- B. Multi-EAOS Decoding Phase ---\n",
    "        batch_size = input_ids.size(0)\n",
    "\n",
    "        # Nh√¢n b·∫£n Queries cho c·∫£ Batch: (Batch, Max_Quads, Hidden_Dim * 2)\n",
    "        queries = self.quad_queries.unsqueeze(0).expand(batch_size, -1, -1)\n",
    "\n",
    "        # Attention: Queries (Q) soi v√†o LSTM Output (K, V) ƒë·ªÉ l·∫•y th√¥ng tin\n",
    "        # Output: (Batch, Max_Quads, Hidden_Dim * 2)\n",
    "        attn_out, _ = self.attention(query=queries, key=lstm_out, value=lstm_out)\n",
    "\n",
    "        attn_out = self.dropout(attn_out)\n",
    "\n",
    "        # --- C. Prediction Phase ---\n",
    "        # M·ªói vector trong attn_out ƒë·∫°i di·ªán cho 1 b·ªô t·ª© (Quad)\n",
    "\n",
    "        # 1. D·ª± ƒëo√°n v·ªã tr√≠ (Logits: Batch, Max_Quads, Max_Len)\n",
    "        e_start_logits = self.fc_e_start(attn_out)\n",
    "        e_end_logits   = self.fc_e_end(attn_out)\n",
    "        o_start_logits = self.fc_o_start(attn_out)\n",
    "        o_end_logits   = self.fc_o_end(attn_out)\n",
    "\n",
    "        # 2. D·ª± ƒëo√°n ph√¢n lo·∫°i (Logits: Batch, Max_Quads, Num_Classes)\n",
    "        aspect_logits    = self.fc_aspect(attn_out)\n",
    "        sentiment_logits = self.fc_sentiment(attn_out)\n",
    "\n",
    "        return {\n",
    "            \"e_start\": e_start_logits,\n",
    "            \"e_end\": e_end_logits,\n",
    "            \"o_start\": o_start_logits,\n",
    "            \"o_end\": o_end_logits,\n",
    "            \"aspect\": aspect_logits,\n",
    "            \"sentiment\": sentiment_logits\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d75109",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gi·∫£ l·∫≠p input t·ª´ Step 2\n",
    "dummy_input_ids = torch.randint(0, 1000, (2, 256)) # Batch size = 2, Max len = 256\n",
    "dummy_mask = torch.ones((2, 256))\n",
    "\n",
    "# Kh·ªüi t·∫°o model\n",
    "model = MultiEAOSModel(max_quads=4)\n",
    "\n",
    "# Forward pass\n",
    "outputs = model(dummy_input_ids, dummy_mask)\n",
    "\n",
    "print(\"K√≠ch th∆∞·ªõc ƒë·∫ßu ra:\")\n",
    "print(\"Entity Start Logits:\", outputs['e_start'].shape) # K√¨ v·ªçng: [2, 4, 256]\n",
    "print(\"Aspect Logits:      \", outputs['aspect'].shape)  # K√¨ v·ªçng: [2, 4, 11] (11 Aspect categories)\n",
    "print(\"Sentiment Logits:   \", outputs['sentiment'].shape) # K√¨ v·ªçng: [2, 4, 3] (3 Sentiment classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06684f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from tqdm import tqdm # Th∆∞ vi·ªán t·∫°o thanh ti·∫øn tr√¨nh (loading bar)\n",
    "\n",
    "class MultiEAOSLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MultiEAOSLoss, self).__init__()\n",
    "        # ignore_index=-1 gi√∫p b·ªè qua c√°c v·ªã tr√≠ padding trong qu√° tr√¨nh t√≠nh loss\n",
    "        self.criterion = nn.CrossEntropyLoss(ignore_index=-1)\n",
    "\n",
    "    def forward(self, outputs, targets):\n",
    "        \"\"\"\n",
    "        outputs: Dictionary ch·ª©a logits t·ª´ model (e_start, e_end, ..., sentiment)\n",
    "        targets: Tensor [Batch, Quads, 6] ch·ª©a nh√£n ƒë√∫ng\n",
    "                 Th·ª© t·ª± c·ªôt: 0:e_s, 1:e_e, 2:o_s, 3:o_e, 4:aspect, 5:sentiment\n",
    "        \"\"\"\n",
    "        # Ch√∫ng ta g·ªôp (Flatten) dimension Batch v√† Quads l·∫°i ƒë·ªÉ t√≠nh Loss m·ªôt th·ªÉ\n",
    "        # Shape Logits: (Batch * Quads, Num_Classes)\n",
    "        # Shape Targets: (Batch * Quads)\n",
    "\n",
    "        # 1. Loss cho v·ªã tr√≠ Entity (Start & End)\n",
    "        loss_e_start = self.criterion(outputs['e_start'].view(-1, outputs['e_start'].shape[-1]),\n",
    "                                      targets[:, :, 0].view(-1))\n",
    "        loss_e_end   = self.criterion(outputs['e_end'].view(-1, outputs['e_end'].shape[-1]),\n",
    "                                      targets[:, :, 1].view(-1))\n",
    "\n",
    "        # 2. Loss cho v·ªã tr√≠ Opinion (Start & End)\n",
    "        loss_o_start = self.criterion(outputs['o_start'].view(-1, outputs['o_start'].shape[-1]),\n",
    "                                      targets[:, :, 2].view(-1))\n",
    "        loss_o_end   = self.criterion(outputs['o_end'].view(-1, outputs['o_end'].shape[-1]),\n",
    "                                      targets[:, :, 3].view(-1))\n",
    "\n",
    "        # 3. Loss cho Aspect & Sentiment\n",
    "        loss_aspect    = self.criterion(outputs['aspect'].view(-1, outputs['aspect'].shape[-1]),\n",
    "                                        targets[:, :, 4].view(-1))\n",
    "        loss_sentiment = self.criterion(outputs['sentiment'].view(-1, outputs['sentiment'].shape[-1]),\n",
    "                                        targets[:, :, 5].view(-1))\n",
    "\n",
    "        # T·ªïng h·ª£p Loss (c√≥ th·ªÉ th√™m tr·ªçng s·ªë weight n·∫øu mu·ªën ∆∞u ti√™n task n√†o h∆°n)\n",
    "        total_loss = loss_e_start + loss_e_end + loss_o_start + loss_o_end + loss_aspect + loss_sentiment\n",
    "        return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09be373a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# Create model directories\n",
    "MODEL_DIR = \"./models\"\n",
    "CHECKPOINT_DIR = os.path.join(MODEL_DIR, \"checkpoints\")\n",
    "BEST_MODEL_DIR = os.path.join(MODEL_DIR, \"best_model\")\n",
    "\n",
    "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
    "os.makedirs(BEST_MODEL_DIR, exist_ok=True)\n",
    "\n",
    "def save_checkpoint(model, optimizer, epoch, train_loss, val_loss, filename):\n",
    "    \"\"\"\n",
    "    Save training checkpoint with all necessary information\n",
    "    \"\"\"\n",
    "    checkpoint = {\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'train_loss': train_loss,\n",
    "        'val_loss': val_loss,\n",
    "        'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    }\n",
    "    torch.save(checkpoint, filename)\n",
    "    print(f\"‚úÖ Saved checkpoint: {filename}\")\n",
    "\n",
    "def save_best_model(model, tokenizer, epoch, val_loss, metrics=None):\n",
    "    \"\"\"\n",
    "    Save the best model with all necessary files for deployment\n",
    "    \"\"\"\n",
    "    # Save model weights\n",
    "    model_path = os.path.join(BEST_MODEL_DIR, \"model.pth\")\n",
    "    torch.save(model.state_dict(), model_path)\n",
    "    \n",
    "    # Save model configuration\n",
    "    config = {\n",
    "        \"model_name\": \"vinai/phobert-base\",\n",
    "        \"num_aspects\": 11,\n",
    "        \"num_sentiments\": 3,\n",
    "        \"max_len\": 256,\n",
    "        \"max_quads\": 4,\n",
    "        \"hidden_dim\": 256,\n",
    "        \"best_epoch\": epoch,\n",
    "        \"best_val_loss\": float(val_loss),\n",
    "        \"aspect_map\": ASPECT_MAP,\n",
    "        \"sentiment_map\": SENTIMENT_MAP,\n",
    "        \"saved_at\": datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    }\n",
    "    \n",
    "    if metrics:\n",
    "        config.update(metrics)\n",
    "    \n",
    "    config_path = os.path.join(BEST_MODEL_DIR, \"config.json\")\n",
    "    with open(config_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(config, f, ensure_ascii=False, indent=2)\n",
    "    \n",
    "    print(f\"üèÜ Saved best model at epoch {epoch} with val_loss: {val_loss:.4f}\")\n",
    "    \n",
    "def load_checkpoint(model, optimizer, filename, device):\n",
    "    \"\"\"\n",
    "    Load training checkpoint to resume training\n",
    "    \"\"\"\n",
    "    if not os.path.isfile(filename):\n",
    "        print(f\"‚ö†Ô∏è  Checkpoint not found: {filename}. Training from scratch.\")\n",
    "        return model, optimizer, 0, float('inf')\n",
    "    \n",
    "    print(f\"üîÑ Loading checkpoint from: {filename}\")\n",
    "    checkpoint = torch.load(filename, map_location=device, weights_only=False)\n",
    "    \n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    \n",
    "    if optimizer:\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    \n",
    "    start_epoch = checkpoint['epoch'] + 1\n",
    "    best_val_loss = checkpoint.get('val_loss', float('inf'))\n",
    "    \n",
    "    print(f\"‚úÖ Resumed from epoch {checkpoint['epoch']}, best val_loss: {best_val_loss:.4f}\")\n",
    "    return model, optimizer, start_epoch, best_val_loss\n",
    "\n",
    "def load_model_for_inference(model_class, device):\n",
    "    \"\"\"\n",
    "    Load the best saved model for inference (backend use)\n",
    "    \"\"\"\n",
    "    config_path = os.path.join(BEST_MODEL_DIR, \"config.json\")\n",
    "    model_path = os.path.join(BEST_MODEL_DIR, \"model.pth\")\n",
    "    \n",
    "    if not os.path.exists(config_path) or not os.path.exists(model_path):\n",
    "        raise FileNotFoundError(\"Best model not found. Please train the model first.\")\n",
    "    \n",
    "    # Load configuration\n",
    "    with open(config_path, 'r', encoding='utf-8') as f:\n",
    "        config = json.load(f)\n",
    "    \n",
    "    # Initialize model with saved config\n",
    "    model = model_class(\n",
    "        model_name=config['model_name'],\n",
    "        num_aspects=config['num_aspects'],\n",
    "        num_sentiments=config['num_sentiments'],\n",
    "        max_len=config['max_len'],\n",
    "        max_quads=config['max_quads'],\n",
    "        hidden_dim=config['hidden_dim']\n",
    "    ).to(device)\n",
    "    \n",
    "    # Load weights\n",
    "    model.load_state_dict(torch.load(model_path, map_location=device, weights_only=True))\n",
    "    model.eval()\n",
    "    \n",
    "    print(f\"‚úÖ Loaded model from epoch {config['best_epoch']} with val_loss: {config['best_val_loss']:.4f}\")\n",
    "    return model, config\n",
    "\n",
    "print(\"üìÅ Model directories created:\")\n",
    "print(f\"  - Checkpoints: {CHECKPOINT_DIR}\")\n",
    "print(f\"  - Best model: {BEST_MODEL_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b512706",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "BATCH_SIZE = 8\n",
    "LR = 2e-5\n",
    "EPOCHS = 200\n",
    "SAVE_EVERY = 10  # Save checkpoint every N epochs\n",
    "EARLY_STOP_PATIENCE = 20  # Stop if no improvement for N epochs\n",
    "\n",
    "def calculate_metrics(outputs, targets):\n",
    "    \"\"\"\n",
    "    Calculate Accuracy, Precision, Recall, F1-score for EAOS predictions\n",
    "    \n",
    "    A prediction is considered correct (TP) if ALL 6 components match:\n",
    "    - entity_start, entity_end, opinion_start, opinion_end, aspect, sentiment\n",
    "    \n",
    "    Returns:\n",
    "        dict: Contains accuracy, precision, recall, f1_score\n",
    "    \"\"\"\n",
    "    batch_size, max_quads = targets.shape[0], targets.shape[1]\n",
    "    \n",
    "    # Get predictions (argmax)\n",
    "    pred_e_start = torch.argmax(outputs['e_start'], dim=-1)  # [batch, quads]\n",
    "    pred_e_end = torch.argmax(outputs['e_end'], dim=-1)\n",
    "    pred_o_start = torch.argmax(outputs['o_start'], dim=-1)\n",
    "    pred_o_end = torch.argmax(outputs['o_end'], dim=-1)\n",
    "    pred_aspect = torch.argmax(outputs['aspect'], dim=-1)\n",
    "    pred_sentiment = torch.argmax(outputs['sentiment'], dim=-1)\n",
    "    \n",
    "    # Flatten predictions and targets\n",
    "    # Shape: [batch * quads]\n",
    "    pred_e_start = pred_e_start.view(-1)\n",
    "    pred_e_end = pred_e_end.view(-1)\n",
    "    pred_o_start = pred_o_start.view(-1)\n",
    "    pred_o_end = pred_o_end.view(-1)\n",
    "    pred_aspect = pred_aspect.view(-1)\n",
    "    pred_sentiment = pred_sentiment.view(-1)\n",
    "    \n",
    "    true_e_start = targets[:, :, 0].view(-1)\n",
    "    true_e_end = targets[:, :, 1].view(-1)\n",
    "    true_o_start = targets[:, :, 2].view(-1)\n",
    "    true_o_end = targets[:, :, 3].view(-1)\n",
    "    true_aspect = targets[:, :, 4].view(-1)\n",
    "    true_sentiment = targets[:, :, 5].view(-1)\n",
    "    \n",
    "    # Create mask for valid targets (not padding, i.e., != -1)\n",
    "    valid_mask = (true_e_start != -1)\n",
    "    \n",
    "    if valid_mask.sum() == 0:\n",
    "        return {'accuracy': 0.0, 'precision': 0.0, 'recall': 0.0, 'f1_score': 0.0}\n",
    "    \n",
    "    # Check if all 6 components match (strict matching)\n",
    "    all_match = (\n",
    "        (pred_e_start == true_e_start) &\n",
    "        (pred_e_end == true_e_end) &\n",
    "        (pred_o_start == true_o_start) &\n",
    "        (pred_o_end == true_o_end) &\n",
    "        (pred_aspect == true_aspect) &\n",
    "        (pred_sentiment == true_sentiment)\n",
    "    )\n",
    "    \n",
    "    # Apply mask to only count valid predictions\n",
    "    all_match = all_match & valid_mask\n",
    "    \n",
    "    # True Positives: predictions that match ground truth\n",
    "    tp = all_match.sum().item()\n",
    "    \n",
    "    # Total valid ground truth samples\n",
    "    total_valid = valid_mask.sum().item()\n",
    "    \n",
    "    # For EAOS, we consider:\n",
    "    # - TP: Correct predictions\n",
    "    # - FP: Incorrect predictions (where target exists)\n",
    "    # - FN: Missed predictions (same as FP in this case since we have fixed slots)\n",
    "    fp = total_valid - tp\n",
    "    fn = total_valid - tp\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = tp / total_valid if total_valid > 0 else 0.0\n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0.0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0.0\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_score': f1_score\n",
    "    }\n",
    "\n",
    "def train_epoch(model, data_loader, optimizer, loss_fn, device):\n",
    "    \"\"\"Train for one epoch\"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    all_metrics = {'accuracy': 0, 'precision': 0, 'recall': 0, 'f1_score': 0}\n",
    "    \n",
    "    progress_bar = tqdm(data_loader, desc=\"Training\")\n",
    "    \n",
    "    for batch in progress_bar:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        targets = batch['targets'].to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input_ids, attention_mask)\n",
    "        loss = loss_fn(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Calculate metrics\n",
    "        metrics = calculate_metrics(outputs, targets)\n",
    "        for key in all_metrics:\n",
    "            all_metrics[key] += metrics[key]\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        progress_bar.set_postfix({\n",
    "            'loss': f\"{loss.item():.4f}\",\n",
    "            'f1': f\"{metrics['f1_score']:.4f}\"\n",
    "        })\n",
    "    \n",
    "    avg_loss = total_loss / len(data_loader)\n",
    "    avg_metrics = {key: val / len(data_loader) for key, val in all_metrics.items()}\n",
    "    \n",
    "    return avg_loss, avg_metrics\n",
    "\n",
    "def validate_epoch(model, data_loader, loss_fn, device):\n",
    "    \"\"\"Validate the model\"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    all_metrics = {'accuracy': 0, 'precision': 0, 'recall': 0, 'f1_score': 0}\n",
    "    \n",
    "    progress_bar = tqdm(data_loader, desc=\"Validation\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in progress_bar:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            targets = batch['targets'].to(device)\n",
    "            \n",
    "            outputs = model(input_ids, attention_mask)\n",
    "            loss = loss_fn(outputs, targets)\n",
    "            \n",
    "            # Calculate metrics\n",
    "            metrics = calculate_metrics(outputs, targets)\n",
    "            for key in all_metrics:\n",
    "                all_metrics[key] += metrics[key]\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            progress_bar.set_postfix({\n",
    "                'val_loss': f\"{loss.item():.4f}\",\n",
    "                'f1': f\"{metrics['f1_score']:.4f}\"\n",
    "            })\n",
    "    \n",
    "    avg_loss = total_loss / len(data_loader)\n",
    "    avg_metrics = {key: val / len(data_loader) for key, val in all_metrics.items()}\n",
    "    \n",
    "    return avg_loss, avg_metrics\n",
    "\n",
    "def run_training(train_dataset, val_dataset, resume_from=None):\n",
    "    \"\"\"\n",
    "    Main training function with validation and model saving\n",
    "    \n",
    "    Args:\n",
    "        train_dataset: Training dataset\n",
    "        val_dataset: Validation dataset\n",
    "        resume_from: Path to checkpoint to resume from (optional)\n",
    "    \"\"\"\n",
    "    # Create data loaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    \n",
    "    # Initialize model and loss\n",
    "    model = MultiEAOSModel(max_quads=4).to(DEVICE)\n",
    "    loss_fn = MultiEAOSLoss().to(DEVICE)\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=LR)\n",
    "    \n",
    "    # Resume from checkpoint if specified\n",
    "    start_epoch = 0\n",
    "    best_val_loss = float('inf')\n",
    "    best_val_f1 = 0.0\n",
    "    patience_counter = 0\n",
    "    \n",
    "    if resume_from:\n",
    "        model, optimizer, start_epoch, best_val_loss = load_checkpoint(\n",
    "            model, optimizer, resume_from, DEVICE\n",
    "        )\n",
    "    \n",
    "    print(f\"üöÄ Starting training on: {DEVICE}\")\n",
    "    print(f\"üìä Train samples: {len(train_dataset)}, Val samples: {len(val_dataset)}\")\n",
    "    print(f\"üéØ Batch size: {BATCH_SIZE}, Learning rate: {LR}\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    # Training loop\n",
    "    for epoch in range(start_epoch, EPOCHS):\n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"Epoch {epoch + 1}/{EPOCHS}\")\n",
    "        print(f\"{'='*70}\")\n",
    "        \n",
    "        # Train\n",
    "        train_loss, train_metrics = train_epoch(model, train_loader, optimizer, loss_fn, DEVICE)\n",
    "        \n",
    "        # Validate\n",
    "        val_loss, val_metrics = validate_epoch(model, val_loader, loss_fn, DEVICE)\n",
    "        \n",
    "        print(f\"\\nüìà Epoch {epoch + 1} Results:\")\n",
    "        print(f\"   Train Loss: {train_loss:.4f}\")\n",
    "        print(f\"   Train Metrics:\")\n",
    "        print(f\"      - Accuracy:  {train_metrics['accuracy']:.4f}\")\n",
    "        print(f\"      - Precision: {train_metrics['precision']:.4f}\")\n",
    "        print(f\"      - Recall:    {train_metrics['recall']:.4f}\")\n",
    "        print(f\"      - F1-Score:  {train_metrics['f1_score']:.4f}\")\n",
    "        print(f\"\\n   Val Loss:   {val_loss:.4f}\")\n",
    "        print(f\"   Val Metrics:\")\n",
    "        print(f\"      - Accuracy:  {val_metrics['accuracy']:.4f}\")\n",
    "        print(f\"      - Precision: {val_metrics['precision']:.4f}\")\n",
    "        print(f\"      - Recall:    {val_metrics['recall']:.4f}\")\n",
    "        print(f\"      - F1-Score:  {val_metrics['f1_score']:.4f}\")\n",
    "        \n",
    "        # Save checkpoint periodically\n",
    "        if (epoch + 1) % SAVE_EVERY == 0:\n",
    "            checkpoint_path = os.path.join(CHECKPOINT_DIR, f\"checkpoint_epoch_{epoch+1}.pth\")\n",
    "            save_checkpoint(model, optimizer, epoch, train_loss, val_loss, checkpoint_path)\n",
    "        \n",
    "        # Save best model based on validation F1-score\n",
    "        if val_metrics['f1_score'] > best_val_f1:\n",
    "            best_val_f1 = val_metrics['f1_score']\n",
    "            best_val_loss = val_loss\n",
    "            patience_counter = 0\n",
    "            \n",
    "            # Save with metrics\n",
    "            metrics_dict = {\n",
    "                'train_accuracy': train_metrics['accuracy'],\n",
    "                'train_precision': train_metrics['precision'],\n",
    "                'train_recall': train_metrics['recall'],\n",
    "                'train_f1_score': train_metrics['f1_score'],\n",
    "                'val_accuracy': val_metrics['accuracy'],\n",
    "                'val_precision': val_metrics['precision'],\n",
    "                'val_recall': val_metrics['recall'],\n",
    "                'val_f1_score': val_metrics['f1_score']\n",
    "            }\n",
    "            save_best_model(model, tokenizer, epoch + 1, val_loss, metrics=metrics_dict)\n",
    "            print(f\"   üèÜ New best model saved! (F1: {best_val_f1:.4f})\")\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            print(f\"   No improvement ({patience_counter}/{EARLY_STOP_PATIENCE})\")\n",
    "        \n",
    "        # Early stopping\n",
    "        if patience_counter >= EARLY_STOP_PATIENCE:\n",
    "            print(f\"\\n‚ö†Ô∏è  Early stopping triggered after {epoch + 1} epochs\")\n",
    "            print(f\"   Best val F1-score: {best_val_f1:.4f}\")\n",
    "            print(f\"   Best val loss: {best_val_loss:.4f}\")\n",
    "            break\n",
    "        \n",
    "        # Save latest checkpoint for resuming\n",
    "        latest_checkpoint = os.path.join(CHECKPOINT_DIR, \"latest_checkpoint.pth\")\n",
    "        save_checkpoint(model, optimizer, epoch, train_loss, val_loss, latest_checkpoint)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"‚úÖ Training completed!\")\n",
    "    print(f\"üèÜ Best validation F1-score: {best_val_f1:.4f}\")\n",
    "    print(f\"üìÅ Best model saved in: {BEST_MODEL_DIR}\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Example usage (commented out - uncomment to run):\n",
    "# trained_model = run_training(train_dataset, val_dataset)\n",
    "# \n",
    "# To resume training from checkpoint:\n",
    "# trained_model = run_training(train_dataset, val_dataset, \n",
    "#                              resume_from=\"./models/checkpoints/latest_checkpoint.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8b10b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# EVALUATION FUNCTION FOR TEST SET\n",
    "# ============================================================================\n",
    "\n",
    "def evaluate_model(model, test_dataset, device=DEVICE, batch_size=8):\n",
    "    \"\"\"\n",
    "    Comprehensive evaluation of the model on test set\n",
    "    \n",
    "    Args:\n",
    "        model: Trained MultiEAOSModel\n",
    "        test_dataset: Test dataset\n",
    "        device: torch device\n",
    "        batch_size: Batch size for evaluation\n",
    "    \n",
    "    Returns:\n",
    "        dict: Evaluation metrics\n",
    "    \"\"\"\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    loss_fn = MultiEAOSLoss().to(device)\n",
    "    \n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    all_metrics = {'accuracy': 0, 'precision': 0, 'recall': 0, 'f1_score': 0}\n",
    "    \n",
    "    print(\"üîç Evaluating model on test set...\")\n",
    "    progress_bar = tqdm(test_loader, desc=\"Evaluation\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in progress_bar:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            targets = batch['targets'].to(device)\n",
    "            \n",
    "            outputs = model(input_ids, attention_mask)\n",
    "            loss = loss_fn(outputs, targets)\n",
    "            \n",
    "            # Calculate metrics\n",
    "            metrics = calculate_metrics(outputs, targets)\n",
    "            for key in all_metrics:\n",
    "                all_metrics[key] += metrics[key]\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            progress_bar.set_postfix({\n",
    "                'loss': f\"{loss.item():.4f}\",\n",
    "                'f1': f\"{metrics['f1_score']:.4f}\"\n",
    "            })\n",
    "    \n",
    "    avg_loss = total_loss / len(test_loader)\n",
    "    avg_metrics = {key: val / len(test_loader) for key, val in all_metrics.items()}\n",
    "    \n",
    "    # Print detailed results\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"üìä EVALUATION RESULTS\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"Test Loss:      {avg_loss:.4f}\")\n",
    "    print(f\"Accuracy:       {avg_metrics['accuracy']:.4f} ({avg_metrics['accuracy']*100:.2f}%)\")\n",
    "    print(f\"Precision:      {avg_metrics['precision']:.4f} ({avg_metrics['precision']*100:.2f}%)\")\n",
    "    print(f\"Recall:         {avg_metrics['recall']:.4f} ({avg_metrics['recall']*100:.2f}%)\")\n",
    "    print(f\"F1-Score:       {avg_metrics['f1_score']:.4f} ({avg_metrics['f1_score']*100:.2f}%)\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    return {\n",
    "        'test_loss': avg_loss,\n",
    "        **avg_metrics\n",
    "    }\n",
    "\n",
    "# ============================================================================\n",
    "# TRAINING EXECUTION\n",
    "# ============================================================================\n",
    "\n",
    "# Run training with train/validation split\n",
    "trained_model = run_training(train_dataset, val_dataset)\n",
    "\n",
    "# Evaluate on validation set (can be used as test set if you don't have separate test data)\n",
    "print(\"\\n\\n\" + \"üéØ FINAL EVALUATION ON VALIDATION SET \" + \"\\n\")\n",
    "final_metrics = evaluate_model(trained_model, val_dataset)\n",
    "\n",
    "# To resume training from a checkpoint, uncomment this line:\n",
    "# trained_model = run_training(train_dataset, val_dataset, \n",
    "#                              resume_from=\"./models/checkpoints/latest_checkpoint.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ca7e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# C√°c map ng∆∞·ª£c ƒë·ªÉ chuy·ªÉn s·ªë th√†nh ch·ªØ\n",
    "ID2ASPECT = {v: k for k, v in ASPECT_MAP.items() if v != -1}\n",
    "ID2SENTIMENT = {v: k for k, v in SENTIMENT_MAP.items() if v != -1}\n",
    "\n",
    "def decode_prediction(model, tokenizer, text, device, max_len=256):\n",
    "    model.eval()\n",
    "\n",
    "    # 1. Ti·ªÅn x·ª≠ l√Ω input (Tokenize)\n",
    "    inputs = tokenizer(\n",
    "        text,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        max_length=max_len,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    input_ids = inputs['input_ids'].to(device)\n",
    "    attention_mask = inputs['attention_mask'].to(device)\n",
    "\n",
    "    # 2. Ch·∫°y m√¥ h√¨nh\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids, attention_mask)\n",
    "\n",
    "    # 3. Gi·∫£i m√£ k·∫øt qu·∫£ (Decoding)\n",
    "    results = []\n",
    "\n",
    "    # L·∫•y ra c√°c index c√≥ x√°c su·∫•t cao nh·∫•t (Argmax)\n",
    "    # Shape: [1, 5] (Batch=1, Quads=5)\n",
    "    pred_e_start = torch.argmax(outputs['e_start'], dim=-1)[0]\n",
    "    pred_e_end   = torch.argmax(outputs['e_end'], dim=-1)[0]\n",
    "    pred_o_start = torch.argmax(outputs['o_start'], dim=-1)[0]\n",
    "    pred_o_end   = torch.argmax(outputs['o_end'], dim=-1)[0]\n",
    "    pred_aspect  = torch.argmax(outputs['aspect'], dim=-1)[0]\n",
    "    pred_sent    = torch.argmax(outputs['sentiment'], dim=-1)[0]\n",
    "\n",
    "    # L·∫•y token g·ªëc ƒë·ªÉ decode text\n",
    "    tokens = tokenizer.convert_ids_to_tokens(input_ids[0])\n",
    "\n",
    "    # Duy·ªát qua t·ª´ng slot trong 5 slots d·ª± ƒëo√°n\n",
    "    for i in range(len(pred_e_start)):\n",
    "        e_s, e_e = pred_e_start[i].item(), pred_e_end[i].item()\n",
    "        o_s, o_e = pred_o_start[i].item(), pred_o_end[i].item()\n",
    "\n",
    "        # --- B·ªò L·ªåC R√ÅC (HEURISTICS) ---\n",
    "        # Lo·∫°i b·ªè n·∫øu Start > End ho·∫∑c ch·ªâ tr·ªè v√†o token ƒë·∫∑c bi·ªát (CLS/SEP/PAD)\n",
    "        # Tokenizer PhoBERT: 0=<s>, 2=</s>, 1=<pad>\n",
    "        if e_s > e_e or o_s > o_e: continue\n",
    "        if e_s == 0 or e_e == 0: continue # B·ªè qua n·∫øu tr·ªè v√†o [CLS]\n",
    "        if e_s >= len(tokens) or o_s >= len(tokens): continue\n",
    "\n",
    "        # Decode text t·ª´ token index\n",
    "        # convert_tokens_to_string s·∫Ω n·ªëi l·∫°i c√°c t·ª´ v√† x·ª≠ l√Ω d·∫•u '_'\n",
    "        entity_tokens = tokens[e_s : e_e + 1]\n",
    "        opinion_tokens = tokens[o_s : o_e + 1]\n",
    "\n",
    "        entity_text = tokenizer.convert_tokens_to_string(entity_tokens).replace('_', ' ')\n",
    "        opinion_text = tokenizer.convert_tokens_to_string(opinion_tokens).replace('_', ' ')\n",
    "\n",
    "        # L·∫•y nh√£n ph√¢n lo·∫°i\n",
    "        aspect_label = ID2ASPECT.get(pred_aspect[i].item(), \"Kh√°c\")\n",
    "        sentiment_label = ID2SENTIMENT.get(pred_sent[i].item(), \"Trung t√≠nh\")\n",
    "\n",
    "        # Ch·ªâ l·∫•y k·∫øt qu·∫£ n·∫øu text kh√¥ng r·ªóng\n",
    "        if entity_text.strip() and opinion_text.strip():\n",
    "            results.append({\n",
    "                \"entity\": entity_text,\n",
    "                \"aspect\": aspect_label,\n",
    "                \"opinion\": opinion_text,\n",
    "                \"sentiment\": sentiment_label\n",
    "            })\n",
    "\n",
    "    return results\n",
    "\n",
    "# --- CH·∫†Y TH·ª¨ NGHI·ªÜM ---\n",
    "# sample_text = \"Ch∆∞∆°ng tr√¨nh m√πa n√†y ch√°n qu√°, MC d·∫´n nh·∫°t nh·∫Ωo\"\n",
    "# preds = decode_prediction(trained_model, tokenizer, sample_text, DEVICE)\n",
    "# print(\"K·∫øt qu·∫£ d·ª± ƒëo√°n:\", preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nuo6ciaen5s",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# BACKEND DEPLOYMENT UTILITY\n",
    "# ============================================================================\n",
    "\n",
    "class EAOSInference:\n",
    "    \"\"\"\n",
    "    Production-ready inference class for backend deployment\n",
    "    This class can be imported and used in your FastAPI/Flask backend\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, model_dir=\"./models/best_model\", device=None):\n",
    "        \"\"\"\n",
    "        Initialize the inference model\n",
    "        \n",
    "        Args:\n",
    "            model_dir: Directory containing model.pth and config.json\n",
    "            device: torch device (auto-detected if None)\n",
    "        \"\"\"\n",
    "        self.device = device or torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.model_dir = model_dir\n",
    "        \n",
    "        # Load configuration\n",
    "        config_path = os.path.join(model_dir, \"config.json\")\n",
    "        with open(config_path, 'r', encoding='utf-8') as f:\n",
    "            self.config = json.load(f)\n",
    "        \n",
    "        # Create reverse mappings\n",
    "        self.id2aspect = {v: k for k, v in self.config['aspect_map'].items()}\n",
    "        self.id2sentiment = {v: k for k, v in self.config['sentiment_map'].items()}\n",
    "        \n",
    "        # Load tokenizer\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(self.config['model_name'])\n",
    "        \n",
    "        # Initialize and load model\n",
    "        self.model = MultiEAOSModel(\n",
    "            model_name=self.config['model_name'],\n",
    "            num_aspects=self.config['num_aspects'],\n",
    "            num_sentiments=self.config['num_sentiments'],\n",
    "            max_len=self.config['max_len'],\n",
    "            max_quads=self.config['max_quads'],\n",
    "            hidden_dim=self.config['hidden_dim']\n",
    "        ).to(self.device)\n",
    "        \n",
    "        # Load weights\n",
    "        model_path = os.path.join(model_dir, \"model.pth\")\n",
    "        self.model.load_state_dict(torch.load(model_path, map_location=self.device, weights_only=True))\n",
    "        self.model.eval()\n",
    "        \n",
    "        print(f\"‚úÖ Model loaded successfully\")\n",
    "        print(f\"   Device: {self.device}\")\n",
    "        print(f\"   Model from epoch: {self.config['best_epoch']}\")\n",
    "        print(f\"   Best val_loss: {self.config['best_val_loss']:.4f}\")\n",
    "    \n",
    "    def predict(self, text, confidence_threshold=0.5):\n",
    "        \"\"\"\n",
    "        Predict EAOS quadruples from input text\n",
    "        \n",
    "        Args:\n",
    "            text: Input Vietnamese text\n",
    "            confidence_threshold: Minimum confidence score (0-1)\n",
    "        \n",
    "        Returns:\n",
    "            List of dictionaries containing predictions\n",
    "        \"\"\"\n",
    "        # Tokenize\n",
    "        inputs = self.tokenizer(\n",
    "            text,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            max_length=self.config['max_len'],\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        input_ids = inputs['input_ids'].to(self.device)\n",
    "        attention_mask = inputs['attention_mask'].to(self.device)\n",
    "        \n",
    "        # Run inference\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(input_ids, attention_mask)\n",
    "        \n",
    "        # Decode predictions\n",
    "        results = []\n",
    "        tokens = self.tokenizer.convert_ids_to_tokens(input_ids[0])\n",
    "        \n",
    "        # Get predictions with argmax\n",
    "        pred_e_start = torch.argmax(outputs['e_start'], dim=-1)[0]\n",
    "        pred_e_end = torch.argmax(outputs['e_end'], dim=-1)[0]\n",
    "        pred_o_start = torch.argmax(outputs['o_start'], dim=-1)[0]\n",
    "        pred_o_end = torch.argmax(outputs['o_end'], dim=-1)[0]\n",
    "        pred_aspect = torch.argmax(outputs['aspect'], dim=-1)[0]\n",
    "        pred_sent = torch.argmax(outputs['sentiment'], dim=-1)[0]\n",
    "        \n",
    "        # Get confidence scores (max softmax probability)\n",
    "        aspect_probs = torch.softmax(outputs['aspect'], dim=-1)[0]\n",
    "        sent_probs = torch.softmax(outputs['sentiment'], dim=-1)[0]\n",
    "        \n",
    "        for i in range(len(pred_e_start)):\n",
    "            e_s, e_e = pred_e_start[i].item(), pred_e_end[i].item()\n",
    "            o_s, o_e = pred_o_start[i].item(), pred_o_end[i].item()\n",
    "            \n",
    "            # Filter invalid predictions\n",
    "            if e_s > e_e or o_s > o_e:\n",
    "                continue\n",
    "            if e_s == 0 or e_e == 0:\n",
    "                continue\n",
    "            if e_s >= len(tokens) or o_s >= len(tokens):\n",
    "                continue\n",
    "            \n",
    "            # Get confidence scores\n",
    "            aspect_conf = aspect_probs[i][pred_aspect[i]].item()\n",
    "            sent_conf = sent_probs[i][pred_sent[i]].item()\n",
    "            avg_confidence = (aspect_conf + sent_conf) / 2\n",
    "            \n",
    "            # Apply confidence threshold\n",
    "            if avg_confidence < confidence_threshold:\n",
    "                continue\n",
    "            \n",
    "            # Decode text\n",
    "            entity_text = self.tokenizer.convert_tokens_to_string(\n",
    "                tokens[e_s:e_e+1]\n",
    "            ).replace('_', ' ').strip()\n",
    "            \n",
    "            opinion_text = self.tokenizer.convert_tokens_to_string(\n",
    "                tokens[o_s:o_e+1]\n",
    "            ).replace('_', ' ').strip()\n",
    "            \n",
    "            # Get labels\n",
    "            aspect_label = self.id2aspect.get(pred_aspect[i].item(), \"Kh√°c\")\n",
    "            sentiment_label = self.id2sentiment.get(pred_sent[i].item(), \"Trung t√≠nh\")\n",
    "            \n",
    "            if entity_text and opinion_text:\n",
    "                results.append({\n",
    "                    \"entity\": entity_text,\n",
    "                    \"aspect\": aspect_label,\n",
    "                    \"opinion\": opinion_text,\n",
    "                    \"sentiment\": sentiment_label,\n",
    "                    \"confidence\": round(avg_confidence, 3)\n",
    "                })\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def predict_batch(self, texts, confidence_threshold=0.5):\n",
    "        \"\"\"\n",
    "        Predict for multiple texts\n",
    "        \n",
    "        Args:\n",
    "            texts: List of input texts\n",
    "            confidence_threshold: Minimum confidence score\n",
    "        \n",
    "        Returns:\n",
    "            List of prediction lists\n",
    "        \"\"\"\n",
    "        return [self.predict(text, confidence_threshold) for text in texts]\n",
    "\n",
    "# Example usage for backend deployment:\n",
    "# inferencer = EAOSInference(model_dir=\"./models/best_model\")\n",
    "# result = inferencer.predict(\"Ch∆∞∆°ng tr√¨nh r·∫•t hay, MC d·∫´n t·ªët\")\n",
    "# print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7282bf96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the inference class (after training)\n",
    "# Uncomment to test:\n",
    "\n",
    "# inferencer = EAOSInference(model_dir=\"./models/best_model\")\n",
    "# \n",
    "# sample_text = \"t√¥i th·∫•y m√πa 2 kh√¥ng hay b·∫±ng m√πa 1 v√¨ m√πa 1 c√≥ tr·∫•n th√†nh m√πa 2 l·∫°i kh√¥ng c√≥\"\n",
    "# predictions = inferencer.predict(sample_text, confidence_threshold=0.3)\n",
    "# \n",
    "# print(\"Input:\", sample_text)\n",
    "# print(\"\\nPredictions:\")\n",
    "# for i, pred in enumerate(predictions, 1):\n",
    "#     print(f\"{i}. Entity: {pred['entity']}\")\n",
    "#     print(f\"   Aspect: {pred['aspect']}\")\n",
    "#     print(f\"   Opinion: {pred['opinion']}\")\n",
    "#     print(f\"   Sentiment: {pred['sentiment']}\")\n",
    "#     print(f\"   Confidence: {pred['confidence']}\")\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7w6dzpuwi98",
   "metadata": {},
   "source": [
    "# üì¶ Backend Integration Guide\n",
    "\n",
    "## How to Use This Model in Your Backend\n",
    "\n",
    "After training, you'll have a `models/best_model/` folder containing:\n",
    "- `model.pth` - The trained model weights\n",
    "- `config.json` - Model configuration and label mappings\n",
    "\n",
    "### Option 1: FastAPI Example\n",
    "\n",
    "```python\n",
    "# backend/main.py\n",
    "from fastapi import FastAPI\n",
    "from pydantic import BaseModel\n",
    "import sys\n",
    "sys.path.append('../Stage2')  # Add notebook path\n",
    "from multi_eaos import EAOSInference  # Import the inference class\n",
    "\n",
    "app = FastAPI()\n",
    "inferencer = EAOSInference(model_dir=\"../Stage2/models/best_model\")\n",
    "\n",
    "class TextInput(BaseModel):\n",
    "    text: str\n",
    "    confidence_threshold: float = 0.5\n",
    "\n",
    "@app.post(\"/predict\")\n",
    "def predict_eaos(input_data: TextInput):\n",
    "    predictions = inferencer.predict(\n",
    "        input_data.text, \n",
    "        confidence_threshold=input_data.confidence_threshold\n",
    "    )\n",
    "    return {\n",
    "        \"input\": input_data.text,\n",
    "        \"predictions\": predictions,\n",
    "        \"count\": len(predictions)\n",
    "    }\n",
    "```\n",
    "\n",
    "### Option 2: Export as Standalone Python Module\n",
    "\n",
    "Create a file `backend/eaos_model.py`:\n",
    "1. Copy the `MultiEAOSModel` class\n",
    "2. Copy the `EAOSInference` class\n",
    "3. Import and use in your backend\n",
    "\n",
    "```python\n",
    "# backend/eaos_model.py\n",
    "# [Copy MultiEAOSModel and EAOSInference classes here]\n",
    "\n",
    "# backend/api.py\n",
    "from eaos_model import EAOSInference\n",
    "\n",
    "model = EAOSInference(\"../models/best_model\")\n",
    "result = model.predict(\"Ch∆∞∆°ng tr√¨nh hay qu√°!\")\n",
    "```\n",
    "\n",
    "### Model Loading in Production\n",
    "\n",
    "```python\n",
    "import torch\n",
    "from eaos_model import EAOSInference\n",
    "\n",
    "# Load once at startup (not per request!)\n",
    "model = EAOSInference(\n",
    "    model_dir=\"./models/best_model\",\n",
    "    device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    ")\n",
    "\n",
    "# Use for predictions\n",
    "def analyze_text(text: str):\n",
    "    return model.predict(text, confidence_threshold=0.5)\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
