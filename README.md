# TV Analytics System - Multi-EAOS Sentiment Analysis

Há»‡ thá»‘ng phÃ¢n tÃ­ch sentiment vÃ  trÃ­ch xuáº¥t EAOS (Entity-Aspect-Opinion-Sentiment) tá»« comments vá» chÆ°Æ¡ng trÃ¬nh TV sá»­ dá»¥ng PhoBERT + Transformer vá»›i Apache Airflow orchestration.

## ğŸ“‹ Tá»•ng quan

Há»‡ thá»‘ng xá»­ lÃ½ batch comments vá» chÆ°Æ¡ng trÃ¬nh TV, sá»­ dá»¥ng mÃ´ hÃ¬nh Multi-EAOS Ä‘á»ƒ trÃ­ch xuáº¥t:
- **Entity** (Thá»±c thá»ƒ): ChÆ°Æ¡ng trÃ¬nh, diá»…n viÃªn, MC, nhÃ¢n váº­t
- **Aspect** (KhÃ­a cáº¡nh): Ná»™i dung, diá»…n xuáº¥t, dÃ n cast, ká»‹ch báº£n, v.v.
- **Opinion** (Ã kiáº¿n): Tá»«/cá»¥m tá»« thá»ƒ hiá»‡n quan Ä‘iá»ƒm
- **Sentiment** (Cáº£m xÃºc): TÃ­ch cá»±c, TiÃªu cá»±c, Trung tÃ­nh

## ğŸ—ï¸ Kiáº¿n trÃºc há»‡ thá»‘ng

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        Data Sources                              â”‚
â”‚  â€¢ Kafka Stream (real-time comments)                            â”‚
â”‚  â€¢ API Submit (manual comments)                                 â”‚
â”‚  â€¢ WebSocket (live comments)                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    MongoDB (Central Database)                    â”‚
â”‚  Collection: comments                                            â”‚
â”‚  â€¢ Unlabeled comments (labels: [])                              â”‚
â”‚  â€¢ Labeled comments (labels: [{entity, aspect, opinion, ...}])  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Apache Airflow (Workflow Orchestration)             â”‚
â”‚                                                                  â”‚
â”‚  DAG: batch_prediction (runs every 1 minute)                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ 1. fetch_comments â†’ MongoDB (5 unlabeled/batch)          â”‚  â”‚
â”‚  â”‚ 2. predict_batch â†’ PySpark Service (HTTP POST)           â”‚  â”‚
â”‚  â”‚ 3. save_predictions â†’ MongoDB (update labels)            â”‚  â”‚
â”‚  â”‚ 4. generate_report â†’ Analytics                           â”‚  â”‚
â”‚  â”‚ 5. cleanup â†’ Temp files                                  â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  PySpark Service (Flask API)                     â”‚
â”‚                                                                  â”‚
â”‚  Port: 5001                                                     â”‚
â”‚  Method: Direct Inference (batch < 10)                          â”‚
â”‚                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ Multi-EAOS Model (PhoBERT + Transformer)                â”‚   â”‚
â”‚  â”‚ â€¢ Encoder: vinai/phobert-base                           â”‚   â”‚
â”‚  â”‚ â€¢ Decoder: Custom Transformer (6 layers)                â”‚   â”‚
â”‚  â”‚ â€¢ Output: EAOS quadruples with confidence               â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  Backend API (FastAPI)                           â”‚
â”‚  Port: 8000                                                     â”‚
â”‚  â€¢ POST /api/submit - Submit new comments                       â”‚
â”‚  â€¢ GET /api/comments/labeled - Get labeled comments             â”‚
â”‚  â€¢ GET /api/analytics/summary - Get analytics                   â”‚
â”‚  â€¢ WebSocket /ws/comments - Live stream                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Frontend (React + Vite)                       â”‚
â”‚  Port: 5173                                                     â”‚
â”‚  â€¢ Comment Stream (labeled comments only)                       â”‚
â”‚  â€¢ Analytics Dashboard (sentiment distribution)                â”‚
â”‚  â€¢ EAOS Visualization                                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ”§ Tech Stack

### Backend & ML
- **Python 3.11**
- **FastAPI** - REST API framework
- **PySpark 3.5** - Distributed processing
- **PyTorch** - Deep learning framework
- **Transformers (Hugging Face)** - PhoBERT model
- **MongoDB** - NoSQL database
- **Apache Kafka** - Message streaming
- **Apache Airflow** - Workflow orchestration

### Frontend
- **React 18** - UI framework
- **TypeScript** - Type safety
- **Vite** - Build tool
- **TailwindCSS** - Styling
- **D3.js** - Data visualization
- **Recharts** - Charts

### DevOps
- **Docker & Docker Compose** - Containerization
- **PostgreSQL** - Airflow metadata
- **Redis** (optional) - Caching

## ğŸ“¦ CÃ i Ä‘áº·t

### Prerequisites
- Docker Desktop
- Python 3.11+
- Node.js 18+

### 1. Clone repository
```bash
git clone <repository-url>
cd FinalProject
```

### 2. Chuáº©n bá»‹ model checkpoints
Äáº·t model weights vÃ o thÆ° má»¥c:
```
application/models/checkpoints/
â”œâ”€â”€ config.json
â”œâ”€â”€ pytorch_model.bin
â””â”€â”€ vocab.txt
```

### 3. Khá»Ÿi Ä‘á»™ng services vá»›i Docker Compose
```bash
cd application
docker-compose up -d
```

Services sáº½ cháº¡y trÃªn:
- **MongoDB**: localhost:27017
- **Kafka**: localhost:9092
- **Airflow UI**: localhost:8080 (admin/admin)
- **PySpark Service**: localhost:5001
- **Backend API**: localhost:8000
- **Frontend**: localhost:5173
- **PostgreSQL** (Airflow): localhost:5432

### 4. Khá»Ÿi Ä‘á»™ng Frontend (development)
```bash
cd application/frontend
npm install
npm run dev
```

## ğŸš€ Sá»­ dá»¥ng

### 1. Submit comments
**Qua API:**
```bash
curl -X POST http://localhost:8000/api/submit \
  -H "Content-Type: application/json" \
  -d '{"text": "ChÆ°Æ¡ng trÃ¬nh ráº¥t hay, MC dáº«n chÆ°Æ¡ng trÃ¬nh tá»‘t"}'
```

**Response:**
```json
{
  "status": "submitted",
  "comment_id": "...",
  "message": "Comment saved. Will be processed in next batch (every 1 min)."
}
```

### 2. Theo dÃµi processing
- Má»Ÿ Airflow UI: http://localhost:8080
- Login: admin/admin
- Xem DAG `batch_prediction`
- Theo dÃµi task execution

### 3. Xem káº¿t quáº£

**Qua API:**
```bash
curl http://localhost:8000/api/comments/labeled?limit=10
```

**Response:**
```json
{
  "total": 14,
  "comments": [
    {
      "_id": "...",
      "text": "ChÆ°Æ¡ng trÃ¬nh ráº¥t hay, MC dáº«n chÆ°Æ¡ng trÃ¬nh tá»‘t",
      "labels": [
        {
          "entity": "ChÆ°Æ¡ng trÃ¬nh",
          "aspect": "Ná»™i dung",
          "opinion": "ráº¥t hay",
          "sentiment": "tÃ­ch cá»±c",
          "confidence": 0.95
        },
        {
          "entity": "MC",
          "aspect": "Dáº«n chÆ°Æ¡ng trÃ¬nh",
          "opinion": "tá»‘t",
          "sentiment": "tÃ­ch cá»±c",
          "confidence": 0.92
        }
      ],
      "predicted_at": "2025-12-27T09:29:00Z"
    }
  ]
}
```

**Qua Frontend:**
- Má»Ÿ http://localhost:5173
- Xem comment stream vá»›i EAOS labels
- Xem analytics dashboard

## âš™ï¸ Cáº¥u hÃ¬nh

### Airflow DAG Settings
File: `application/airflow/dags/batch_prediction_dag.py`

```python
# Táº§n suáº¥t cháº¡y
schedule_interval='*/1 * * * *'  # Má»—i 1 phÃºt

# Batch size
.limit(5)  # 5 comments/batch

# Throughput: ~300 comments/hour
```

### PySpark Service Settings
File: `application/backend/ml/spark_service.py`

```python
# Memory allocation
.config("spark.driver.memory", "2g")

# Inference method threshold
if len(comments) < 10:
    # Use direct inference (faster, stable)
else:
    # Use PySpark PandasUDF (parallel, for large batches)
```

### Model Settings
```python
# Confidence threshold
confidence_threshold = 0.3  # Chá»‰ láº¥y predictions cÃ³ confidence > 0.3
```

## ğŸ“Š Performance

### Current Configuration
- **Batch size**: 5 comments
- **Frequency**: Every 1 minute
- **Method**: Direct inference
- **Throughput**: ~300 comments/hour
- **Latency**: ~2-3 seconds/batch

### Scaling Options
1. **TÄƒng batch size** â†’ 8-9 comments (váº«n dÃ¹ng direct inference)
2. **TÄƒng frequency** â†’ 30 seconds
3. **Parallel DAGs** â†’ Cháº¡y nhiá»u DAG instances

## ğŸ” Monitoring

### Airflow UI
- DAG runs history
- Task logs
- Execution timeline
- Retry/failure tracking

### MongoDB
```bash
# Count unlabeled
db.comments.countDocuments({labels: []})

# Count labeled
db.comments.countDocuments({labels: {$ne: []}})

# Sample EAOS
db.comments.findOne({labels: {$ne: []}})
```

### PySpark Service Health
```bash
curl http://localhost:5001/health
```

Response:
```json
{
  "status": "healthy",
  "model": true,
  "spark": true
}
```

## ğŸ› Troubleshooting

### Airflow DAG khÃ´ng cháº¡y
```bash
# Check scheduler logs
docker logs tv-analytics-airflow-scheduler

# Manually trigger DAG
docker exec tv-analytics-airflow-scheduler \
  airflow dags trigger batch_prediction
```

### PySpark Service lá»—i
```bash
# Check logs
docker logs tv-analytics-pyspark

# Restart service
docker restart tv-analytics-pyspark
```

### MongoDB connection issues
```bash
# Test connection
docker exec tv-analytics-mongodb \
  mongosh "mongodb://admin:admin123@localhost:27017/?authSource=admin"
```

## ğŸ“ Cáº¥u trÃºc thÆ° má»¥c

```
FinalProject/
â”œâ”€â”€ application/
â”‚   â”œâ”€â”€ backend/
â”‚   â”‚   â”œâ”€â”€ api/              # FastAPI routes
â”‚   â”‚   â”œâ”€â”€ ml/               # ML models & PySpark service
â”‚   â”‚   â”‚   â”œâ”€â”€ eaos_model.py
â”‚   â”‚   â”‚   â””â”€â”€ spark_service.py
â”‚   â”‚   â””â”€â”€ services/         # Business logic
â”‚   â”‚
â”‚   â”œâ”€â”€ frontend/
â”‚   â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”‚   â”œâ”€â”€ components/   # React components
â”‚   â”‚   â”‚   â”œâ”€â”€ services/     # API clients
â”‚   â”‚   â”‚   â””â”€â”€ types/        # TypeScript types
â”‚   â”‚   â””â”€â”€ vite.config.ts
â”‚   â”‚
â”‚   â”œâ”€â”€ airflow/
â”‚   â”‚   â””â”€â”€ dags/
â”‚   â”‚       â”œâ”€â”€ batch_prediction_dag.py
â”‚   â”‚       â””â”€â”€ threshold_prediction_dag.py
â”‚   â”‚
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â””â”€â”€ checkpoints/      # Model weights
â”‚   â”‚
â”‚   â””â”€â”€ docker-compose.yml    # Multi-service orchestration
â”‚
â””â”€â”€ README.md
```

## ğŸ” Security Notes

### Production Deployment
1. **Äá»•i passwords máº·c Ä‘á»‹nh**:
   - MongoDB: admin/admin123
   - Airflow: admin/admin
   - PostgreSQL: airflow/airflow

2. **Enable authentication**:
   - API authentication (JWT)
   - CORS configuration
   - Rate limiting

3. **Network security**:
   - Reverse proxy (nginx)
   - SSL/TLS certificates
   - Firewall rules

## ğŸ¤ Contributing

1. Fork the repository
2. Create feature branch: `git checkout -b feature-name`
3. Commit changes: `git commit -m 'Add feature'`
4. Push to branch: `git push origin feature-name`
5. Submit Pull Request

## ğŸ“ License

[MIT License](LICENSE)

## ğŸ‘¥ Authors

- **Team SE363** - UIT
- **Project**: TV Analytics Multi-EAOS System

## ğŸ“§ Contact

For questions or support, please contact the development team.

---

**Note**: This system is designed for educational and research purposes. For production deployment, additional security hardening and performance optimization are recommended.
