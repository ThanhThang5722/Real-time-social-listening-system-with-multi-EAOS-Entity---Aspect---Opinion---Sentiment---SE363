# Há»‡ thá»‘ng TV Analytics - PhÃ¢n tÃ­ch Multi-EAOS Sentiment

Há»‡ thá»‘ng phÃ¢n tÃ­ch tá»± Ä‘á»™ng comments vá» chÆ°Æ¡ng trÃ¬nh TV, trÃ­ch xuáº¥t EAOS (Entity-Aspect-Opinion-Sentiment) báº±ng mÃ´ hÃ¬nh PhoBERT + Transformer vá»›i Ä‘iá»u phá»‘i bá»Ÿi Apache Airflow.

## ğŸ“‹ Giá»›i thiá»‡u

Há»‡ thá»‘ng xá»­ lÃ½ hÃ ng loáº¡t (batch processing) cÃ¡c comments vá» chÆ°Æ¡ng trÃ¬nh truyá»n hÃ¬nh, sá»­ dá»¥ng mÃ´ hÃ¬nh Multi-EAOS Ä‘á»ƒ tá»± Ä‘á»™ng trÃ­ch xuáº¥t:

- **Entity (Thá»±c thá»ƒ)**: ChÆ°Æ¡ng trÃ¬nh, diá»…n viÃªn, MC, nhÃ¢n váº­t, Ä‘á»‹a Ä‘iá»ƒm
- **Aspect (KhÃ­a cáº¡nh)**: Ná»™i dung, diá»…n xuáº¥t, dÃ n cast, ká»‹ch báº£n, Ã¢m nháº¡c, hÃ¬nh áº£nh
- **Opinion (Ã kiáº¿n)**: Tá»« hoáº·c cá»¥m tá»« thá»ƒ hiá»‡n quan Ä‘iá»ƒm cá»§a ngÆ°á»i viáº¿t
- **Sentiment (Cáº£m xÃºc)**: TÃ­ch cá»±c, TiÃªu cá»±c, Trung tÃ­nh

**VÃ­ dá»¥:**
```
Input: "ChÆ°Æ¡ng trÃ¬nh ráº¥t hay, MC dáº«n chÆ°Æ¡ng trÃ¬nh tá»‘t"

Output:
[
  {
    "entity": "ChÆ°Æ¡ng trÃ¬nh",
    "aspect": "Ná»™i dung",
    "opinion": "ráº¥t hay",
    "sentiment": "tÃ­ch cá»±c",
    "confidence": 0.95
  },
  {
    "entity": "MC",
    "aspect": "Dáº«n chÆ°Æ¡ng trÃ¬nh",
    "opinion": "tá»‘t",
    "sentiment": "tÃ­ch cá»±c",
    "confidence": 0.92
  }
]
```

## ğŸ¯ TÃ­nh nÄƒng chÃ­nh

### 1. Thu tháº­p dá»¯ liá»‡u Ä‘a nguá»“n
- âœ… Kafka Stream (real-time streaming)
- âœ… REST API (manual submission)
- âœ… WebSocket (live comments)

### 2. Xá»­ lÃ½ batch tá»± Ä‘á»™ng
- âœ… Apache Airflow orchestration
- âœ… Cháº¡y Ä‘á»‹nh ká»³ má»—i 1 phÃºt
- âœ… Xá»­ lÃ½ 5 comments/batch (~300 comments/giá»)
- âœ… Retry mechanism khi lá»—i

### 3. Machine Learning
- âœ… PhoBERT encoder (vinai/phobert-base)
- âœ… Custom Transformer decoder (6 layers)
- âœ… Direct inference (stable, fast)
- âœ… Confidence threshold filtering

### 4. LÆ°u trá»¯ & Truy váº¥n
- âœ… MongoDB (central database)
- âœ… Labeled/Unlabeled comments tracking
- âœ… Real-time analytics

### 5. Visualization
- âœ… React dashboard
- âœ… Comment stream vá»›i EAOS tags
- âœ… Sentiment distribution charts
- âœ… Entity/Aspect statistics

## ğŸ—ï¸ Kiáº¿n trÃºc

### Luá»“ng dá»¯ liá»‡u chÃ­nh

```
1. Data Input
   â†“
   Kafka/API/WebSocket
   â†“
2. MongoDB Storage (unlabeled)
   â†“
3. Airflow Scheduler (every 1 min)
   â†“
4. Fetch 5 unlabeled comments
   â†“
5. PySpark Service - Direct Inference
   â†“
6. Save predictions to MongoDB
   â†“
7. Frontend polls labeled comments
   â†“
8. Display EAOS visualization
```

### Components

#### Backend Services
- **FastAPI (Port 8000)**: REST API endpoints
- **PySpark Service (Port 5001)**: ML inference service
- **MongoDB (Port 27017)**: Data storage
- **Kafka (Port 9092)**: Message queue
- **Airflow (Port 8080)**: Workflow orchestration

#### Frontend
- **React App (Port 5173)**: User interface
- **WebSocket Client**: Real-time updates

#### Infrastructure
- **Docker Compose**: Multi-container orchestration
- **PostgreSQL (Port 5432)**: Airflow metadata
- **Redis (Optional)**: Caching layer

## ğŸš€ HÆ°á»›ng dáº«n cÃ i Ä‘áº·t

### BÆ°á»›c 1: CÃ i Ä‘áº·t Docker Desktop
Download vÃ  cÃ i Ä‘áº·t tá»«: https://www.docker.com/products/docker-desktop

### BÆ°á»›c 2: Clone repository
```bash
git clone <repository-url>
cd FinalProject/application
```

### BÆ°á»›c 3: Chuáº©n bá»‹ model weights
Táº£i model PhoBERT Ä‘Ã£ fine-tune vÃ  Ä‘áº·t vÃ o:
```
application/models/checkpoints/
â”œâ”€â”€ config.json
â”œâ”€â”€ pytorch_model.bin
â”œâ”€â”€ vocab.txt
â””â”€â”€ training_args.bin (optional)
```

### BÆ°á»›c 4: Khá»Ÿi Ä‘á»™ng services
```bash
docker-compose up -d
```

Äá»£i ~2-3 phÃºt Ä‘á»ƒ cÃ¡c services khá»Ÿi Ä‘á»™ng hoÃ n táº¥t.

### BÆ°á»›c 5: Kiá»ƒm tra services Ä‘ang cháº¡y
```bash
docker ps
```

Báº¡n sáº½ tháº¥y cÃ¡c containers:
- `tv-analytics-mongodb`
- `tv-analytics-kafka`
- `tv-analytics-airflow-scheduler`
- `tv-analytics-airflow-webserver`
- `tv-analytics-pyspark`
- `tv-analytics-postgres`

### BÆ°á»›c 6: Truy cáº­p Airflow UI
1. Má»Ÿ browser: http://localhost:8080
2. Login: `admin` / `admin`
3. Enable DAG `batch_prediction`

### BÆ°á»›c 7: Khá»Ÿi Ä‘á»™ng Frontend (optional)
```bash
cd frontend
npm install
npm run dev
```

Truy cáº­p: http://localhost:5173

## ğŸ’¡ CÃ¡ch sá»­ dá»¥ng

### 1. Submit comments Ä‘á»ƒ xá»­ lÃ½

**CÃ¡ch 1: Qua API**
```bash
curl -X POST http://localhost:8000/api/submit \
  -H "Content-Type: application/json" \
  -d '{
    "text": "Phim hay láº¯m, diá»…n viÃªn Ä‘Ã³ng ráº¥t tá»‘t, ná»™i dung háº¥p dáº«n"
  }'
```

**CÃ¡ch 2: Qua Frontend**
- VÃ o http://localhost:5173
- Nháº­p comment vÃ o form
- Click Submit

**CÃ¡ch 3: Import batch tá»« file**
```bash
# Táº¡o file test_comments.json
python add_test_comments.py
```

### 2. Theo dÃµi xá»­ lÃ½

**Airflow UI:**
1. Má»Ÿ http://localhost:8080
2. Click vÃ o DAG `batch_prediction`
3. Xem Graph View Ä‘á»ƒ theo dÃµi tiáº¿n trÃ¬nh
4. Click vÃ o task Ä‘á»ƒ xem logs chi tiáº¿t

**MongoDB:**
```bash
# Äáº¿m unlabeled comments
docker exec tv-analytics-mongodb mongosh \
  "mongodb://admin:admin123@localhost:27017/tv_analytics?authSource=admin" \
  --quiet --eval "db.comments.countDocuments({labels: []})"

# Äáº¿m labeled comments
docker exec tv-analytics-mongodb mongosh \
  "mongodb://admin:admin123@localhost:27017/tv_analytics?authSource=admin" \
  --quiet --eval "db.comments.countDocuments({labels: {\$ne: []}})"
```

### 3. Xem káº¿t quáº£

**API Endpoint:**
```bash
# Láº¥y 10 comments Ä‘Ã£ Ä‘Æ°á»£c label
curl "http://localhost:8000/api/comments/labeled?limit=10" | python -m json.tool

# Xem analytics summary
curl "http://localhost:8000/api/analytics/summary" | python -m json.tool
```

**Frontend Dashboard:**
- Má»Ÿ http://localhost:5173
- Tab "Comments": Xem stream comments Ä‘Ã£ Ä‘Æ°á»£c label
- Tab "Analytics": Xem biá»ƒu Ä‘á»“ phÃ¢n bá»• sentiment
- Hover vÃ o EAOS tags Ä‘á»ƒ xem chi tiáº¿t

## âš™ï¸ Cáº¥u hÃ¬nh nÃ¢ng cao

### Äiá»u chá»‰nh tá»‘c Ä‘á»™ xá»­ lÃ½

**TÄƒng batch size (nhanh hÆ¡n):**
```python
# File: airflow/dags/batch_prediction_dag.py
# Line 76
).limit(8))  # TÄƒng tá»« 5 lÃªn 8
```

**TÄƒng táº§n suáº¥t cháº¡y:**
```python
# File: airflow/dags/batch_prediction_dag.py
# Line 39
schedule_interval='*/30 * * * *'  # 30 giÃ¢y thay vÃ¬ 1 phÃºt
```

**Throughput Æ°á»›c tÃ­nh:**
- Batch 5, má»—i 1 phÃºt = 300 comments/giá»
- Batch 8, má»—i 1 phÃºt = 480 comments/giá»
- Batch 5, má»—i 30 giÃ¢y = 600 comments/giá»

### Äiá»u chá»‰nh confidence threshold

```python
# File: backend/ml/eaos_model.py
inference = create_inference(
    MODEL_DIR,
    confidence_threshold=0.5  # TÄƒng tá»« 0.3 lÃªn 0.5 Ä‘á»ƒ chá»‰ láº¥y predictions cháº¯c cháº¯n hÆ¡n
)
```

### Cáº¥u hÃ¬nh MongoDB

```yaml
# File: docker-compose.yml
mongodb:
  environment:
    - MONGO_INITDB_ROOT_USERNAME=admin
    - MONGO_INITDB_ROOT_PASSWORD=admin123  # Äá»•i password
```

## ğŸ“Š Hiá»‡u suáº¥t

### Metrics hiá»‡n táº¡i
- **Batch size**: 5 comments
- **Frequency**: 1 phÃºt
- **Method**: Direct inference
- **Throughput**: ~300 comments/giá»
- **Latency**: 2-3 giÃ¢y/batch
- **Accuracy**: ~85-90% (tÃ¹y domain)

### YÃªu cáº§u há»‡ thá»‘ng
- **RAM**: Tá»‘i thiá»ƒu 8GB (recommend 16GB)
- **CPU**: 4 cores
- **Disk**: 20GB (cho Docker images + data)
- **GPU**: KhÃ´ng báº¯t buá»™c (CPU inference)

### Optimization tips
1. **DÃ¹ng GPU**: Uncomment GPU configs trong docker-compose.yml
2. **TÄƒng Spark memory**: Sá»­a `spark.driver.memory` trong spark_service.py
3. **Enable caching**: Uncomment Redis service
4. **Horizontal scaling**: Cháº¡y nhiá»u Airflow workers

## ğŸ” Debugging & Troubleshooting

### DAG khÃ´ng cháº¡y

**Kiá»ƒm tra scheduler:**
```bash
docker logs tv-analytics-airflow-scheduler --tail 100
```

**Trigger manually:**
```bash
docker exec tv-analytics-airflow-scheduler \
  airflow dags trigger batch_prediction
```

**Check DAG file syntax:**
```bash
docker exec tv-analytics-airflow-scheduler \
  python /opt/airflow/dags/batch_prediction_dag.py
```

### PySpark Service lá»—i HTTP 500

**Xem logs:**
```bash
docker logs tv-analytics-pyspark --tail 50
```

**Restart service:**
```bash
docker restart tv-analytics-pyspark
```

**Test health:**
```bash
curl http://localhost:5001/health
```

### MongoDB connection failed

**Kiá»ƒm tra MongoDB running:**
```bash
docker ps | grep mongodb
```

**Test connection:**
```bash
docker exec tv-analytics-mongodb \
  mongosh "mongodb://admin:admin123@localhost:27017/?authSource=admin" \
  --quiet --eval "db.adminCommand({ping: 1})"
```

### Frontend khÃ´ng hiá»ƒn thá»‹ data

**Kiá»ƒm tra API:**
```bash
curl http://localhost:8000/api/comments/labeled
```

**Kiá»ƒm tra CORS:**
```python
# File: backend/api/main.py
# ThÃªm domain vÃ o allowed origins
app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:5173"],
    ...
)
```

## ğŸ“ Cáº¥u trÃºc Project

```
FinalProject/
â”œâ”€â”€ README.md                    # TÃ i liá»‡u (English)
â”œâ”€â”€ README.vi.md                 # TÃ i liá»‡u (Tiáº¿ng Viá»‡t)
â”‚
â””â”€â”€ application/
    â”‚
    â”œâ”€â”€ backend/
    â”‚   â”œâ”€â”€ api/
    â”‚   â”‚   â”œâ”€â”€ main.py          # FastAPI app
    â”‚   â”‚   â”œâ”€â”€ routes.py        # API endpoints
    â”‚   â”‚   â””â”€â”€ websocket.py     # WebSocket handlers
    â”‚   â”‚
    â”‚   â”œâ”€â”€ ml/
    â”‚   â”‚   â”œâ”€â”€ eaos_model.py    # Multi-EAOS model
    â”‚   â”‚   â””â”€â”€ spark_service.py # PySpark HTTP service
    â”‚   â”‚
    â”‚   â”œâ”€â”€ services/
    â”‚   â”‚   â””â”€â”€ comment_stream.py
    â”‚   â”‚
    â”‚   â””â”€â”€ requirements.txt
    â”‚
    â”œâ”€â”€ frontend/
    â”‚   â”œâ”€â”€ src/
    â”‚   â”‚   â”œâ”€â”€ components/      # React components
    â”‚   â”‚   â”‚   â”œâ”€â”€ CommentStream.tsx
    â”‚   â”‚   â”‚   â”œâ”€â”€ EAOSAnalytics.tsx
    â”‚   â”‚   â”‚   â””â”€â”€ SentimentChart.tsx
    â”‚   â”‚   â”‚
    â”‚   â”‚   â”œâ”€â”€ services/
    â”‚   â”‚   â”‚   â””â”€â”€ api.ts       # API client
    â”‚   â”‚   â”‚
    â”‚   â”‚   â”œâ”€â”€ types/
    â”‚   â”‚   â”‚   â””â”€â”€ index.ts     # TypeScript types
    â”‚   â”‚   â”‚
    â”‚   â”‚   â””â”€â”€ App.tsx
    â”‚   â”‚
    â”‚   â”œâ”€â”€ package.json
    â”‚   â””â”€â”€ vite.config.ts
    â”‚
    â”œâ”€â”€ airflow/
    â”‚   â”œâ”€â”€ dags/
    â”‚   â”‚   â”œâ”€â”€ batch_prediction_dag.py
    â”‚   â”‚   â””â”€â”€ threshold_prediction_dag.py
    â”‚   â”‚
    â”‚   â””â”€â”€ logs/                # Task execution logs
    â”‚
    â”œâ”€â”€ models/
    â”‚   â””â”€â”€ checkpoints/         # Model weights
    â”‚       â”œâ”€â”€ config.json
    â”‚       â”œâ”€â”€ pytorch_model.bin
    â”‚       â””â”€â”€ vocab.txt
    â”‚
    â”œâ”€â”€ docker-compose.yml       # Multi-service orchestration
    â”œâ”€â”€ add_test_comments.py     # Script thÃªm test data
    â””â”€â”€ debug_airflow_dag.py     # Debug utilities
```

## ğŸ” Security Checklist

### Development
- âœ… Default passwords (OK cho dev)
- âœ… No authentication (OK cho local)
- âœ… CORS open (OK cho localhost)

### Production Deployment
- âš ï¸ **Báº®T BUá»˜C Ä‘á»•i passwords**:
  ```yaml
  # MongoDB
  MONGO_INITDB_ROOT_PASSWORD: <strong-password>

  # Airflow
  _AIRFLOW_WWW_USER_PASSWORD: <strong-password>

  # PostgreSQL
  POSTGRES_PASSWORD: <strong-password>
  ```

- âš ï¸ **Enable authentication**:
  - API: JWT tokens
  - Airflow: LDAP/OAuth
  - MongoDB: User roles

- âš ï¸ **Network security**:
  - Reverse proxy (nginx)
  - SSL/TLS certificates
  - Firewall rules
  - VPN access

- âš ï¸ **Data protection**:
  - Encrypt sensitive data
  - Backup strategy
  - Access logging

## ğŸ§ª Testing

### Unit Tests
```bash
cd backend
pytest tests/
```

### Integration Tests
```bash
python verify_pyspark_flow.py
python test_airflow_to_pyspark.py
```

### Load Testing
```bash
# Submit 100 test comments
python add_test_comments.py --count 100
```

## ğŸ“ˆ Monitoring

### Airflow Metrics
- DAG success rate
- Task duration
- Failure rate
- Retry count

### System Metrics
```bash
# Docker container stats
docker stats

# MongoDB stats
docker exec tv-analytics-mongodb \
  mongosh --eval "db.serverStatus()"
```

### Application Logs
```bash
# All services
docker-compose logs -f

# Specific service
docker logs tv-analytics-pyspark -f
```

## ğŸ¤ ÄÃ³ng gÃ³p

1. Fork repository
2. Táº¡o branch: `git checkout -b feature/ten-tinh-nang`
3. Commit: `git commit -m 'ThÃªm tÃ­nh nÄƒng X'`
4. Push: `git push origin feature/ten-tinh-nang`
5. Táº¡o Pull Request

## ğŸ“ License

MIT License - Xem file LICENSE Ä‘á»ƒ biáº¿t thÃªm chi tiáº¿t

## ğŸ‘¥ TÃ¡c giáº£

- **Team SE363** - Äáº¡i há»c CÃ´ng nghá»‡ ThÃ´ng tin (UIT)
- **MÃ´n há»c**: PhÃ¢n tÃ­ch vÃ  Thiáº¿t káº¿ Há»‡ thá»‘ng
- **Project**: TV Analytics Multi-EAOS System

## ğŸ“§ LiÃªn há»‡

Má»i tháº¯c máº¯c hoáº·c Ä‘Ã³ng gÃ³p xin liÃªn há»‡ qua:
- Email: [team email]
- GitHub Issues: [repository issues]

---

**LÆ°u Ã½**: Há»‡ thá»‘ng Ä‘Æ°á»£c phÃ¡t triá»ƒn cho má»¥c Ä‘Ã­ch há»c táº­p vÃ  nghiÃªn cá»©u. Khi triá»ƒn khai production, cáº§n bá»• sung thÃªm cÃ¡c biá»‡n phÃ¡p báº£o máº­t vÃ  tá»‘i Æ°u hÃ³a hiá»‡u suáº¥t.

## ğŸ“ TÃ i liá»‡u tham kháº£o

- [Apache Airflow Documentation](https://airflow.apache.org/docs/)
- [PySpark Documentation](https://spark.apache.org/docs/latest/api/python/)
- [PhoBERT Paper](https://arxiv.org/abs/2003.00744)
- [FastAPI Documentation](https://fastapi.tiangolo.com/)
- [React Documentation](https://react.dev/)
